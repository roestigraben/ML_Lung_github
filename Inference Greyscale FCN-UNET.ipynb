{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Inference for greyscale\n",
    "\n",
    "    copying the same flow as the training flow but for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import TensorflowUtils as utils\n",
    "import read_MITSceneParsingData as scene_parsing\n",
    "import datetime\n",
    "import DatasetReader as dataset\n",
    "from six.moves import xrange\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import scipy as scp\n",
    "import scipy.misc as misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dropout, Permute, Add, add\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Deconvolution2D, Cropping2D\n",
    "from keras.layers import InputLayer\n",
    "\n",
    "from fcn_keras2 import fcn32_blank, fcn32_blank_greyscale, fcn_32s_to_16s\n",
    "\n",
    "############ Declarations  ##############\n",
    "\n",
    "\n",
    "\n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'\n",
    "DATA_URL = './Data_zoo/Test.zip'\n",
    "\n",
    "NUM_OF_CLASSESS = 12\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "IMAGE_SIZE = 512\n",
    "LEARNING_RATE = 1e-4\n",
    "MAX_ITERATION = int(1e5 + 1)\n",
    "DEBUG = True\n",
    "\n",
    "LOGS_DIR = \"logs5/\"\n",
    "DATA_DIR = \"Data_zoo/\"\n",
    "LEARNING_RATE = 1e-4\n",
    "MODEL_DIR =\"Model_zoo/\"\n",
    "DATA_URL = './Data_zoo/Test.zip'\n",
    "\n",
    "def inference(image):\n",
    "\n",
    "    fcn32model = fcn32_blank_greyscale(IMAGE_SIZE)\n",
    "\n",
    "    fcn16model = fcn_32s_to_16s(fcn32model)\n",
    "\n",
    "    data = loadmat('pascal-fcn16s-dag.mat', matlab_compatible=False, struct_as_record=False)\n",
    "    l = data['layers']\n",
    "    p = data['params']\n",
    "    description = data['meta'][0,0].classes[0,0].description\n",
    "\n",
    "    class2index = {}\n",
    "    for i, clname in enumerate(description[0,:]):\n",
    "        class2index[str(clname[0])] = i\n",
    "\n",
    "    logits = fcn16model(image)\n",
    "\n",
    "    annotation_pred = tf.argmax(logits, dimension=3, name=\"prediction\")\n",
    "\n",
    "    return tf.expand_dims(annotation_pred, dim=3), logits\n",
    "\n",
    "\n",
    "def train(loss_val, var_list):\n",
    "    optimizer = tf.train.AdamOptimizer(LEARNING_RATE)\n",
    "    grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n",
    "\n",
    "    return optimizer.apply_gradients(grads)\n",
    "\n",
    "\n",
    "keep_probability = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "image = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"input_image\")\n",
    "annotation = tf.placeholder(tf.int32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"annotation\")\n",
    "\n",
    "pred_annotation, logits = inference(image)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=tf.squeeze(annotation, \n",
    "                                                                    squeeze_dims=[3]), name=\"entropy\")))\n",
    "\n",
    "print(\"types on prediction tensors:  \", type(annotation), type(pred_annotation) )\n",
    "\n",
    "# Accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(annotation,3), tf.argmax(pred_annotation,3))\n",
    "acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "trainable_var = tf.trainable_variables()\n",
    "\n",
    "train_op = train(loss, trainable_var)\n",
    "\n",
    "\n",
    "print(\"Setting up dataset reader\")\n",
    "image_options = {'resize': True, 'resize_size': IMAGE_SIZE}\n",
    "\n",
    "validation_dataset_reader = dataset.Dataset_evo_interactive(IMAGE_SIZE, sample_size=200, shape_count = 20, r_min=1, r_max=10)\n",
    "\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)\n",
    "\n",
    "print(\"Setting up Saver...\")\n",
    "saver = tf.train.Saver()\n",
    "summary_writer = tf.summary.FileWriter(LOGS_DIR, sess.graph)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ckpt = tf.train.get_checkpoint_state(LOGS_DIR)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    print(\"Model restored...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def color_image(image, num_classes=20):\n",
    "    import matplotlib as mpl\n",
    "    import matplotlib.cm\n",
    "    norm = mpl.colors.Normalize(vmin=0., vmax=num_classes)\n",
    "    mycm = mpl.cm.get_cmap('Set3')\n",
    "    return mycm(norm(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict_and_display(valid_images, valid_annotations, pred, NUM_OF_CLASSESS):\n",
    "    \n",
    "    unique, counts = np.unique(valid_annotations, return_counts=True)\n",
    "    for n in range(len(unique)):\n",
    "        print(unique[n], counts[n])\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches(18, 18)\n",
    "\n",
    "    \n",
    "\n",
    "    patch = fig.add_subplot(1,3,1)\n",
    "    patch.axes.get_xaxis().set_visible(False)\n",
    "    patch.axes.get_yaxis().set_visible(False)\n",
    "    patch.imshow(valid_images[0]);\n",
    "\n",
    "\n",
    "    new_image = color_image(valid_annotations[0], NUM_OF_CLASSESS)\n",
    "    patch = fig.add_subplot(1,3,2)\n",
    "    patch.axes.get_xaxis().set_visible(False)\n",
    "    patch.axes.get_yaxis().set_visible(False)\n",
    "    patch.imshow(new_image);\n",
    "    \n",
    "    new_image1 = color_image(pred[0], NUM_OF_CLASSESS)\n",
    "    patch = fig.add_subplot(1,3,3)\n",
    "    patch.axes.get_xaxis().set_visible(False)\n",
    "    patch.axes.get_yaxis().set_visible(False)\n",
    "    patch.imshow(new_image1);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "validation_dataset_reader = dataset.Dataset_evo_interactive(IMAGE_SIZE, sample_size=100, shape_count = 1000, r_min=1, r_max=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# run the generator\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "valid_images, valid_annotations = validation_dataset_reader.next_batch(1)\n",
    "print(valid_images.shape)\n",
    "print(valid_annotations.shape)\n",
    "\n",
    "pred = sess.run(pred_annotation, feed_dict={image: valid_images, keep_probability: 1.0})\n",
    "print(pred.shape)\n",
    "\n",
    "predict_and_display(np.squeeze(valid_images,axis=3), np.squeeze(valid_annotations, axis=3),np.squeeze(pred,axis=3), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "comp_images, comp_annotations = validation_dataset_reader.next_batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(comp_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "pred = sess.run(pred_annotation, feed_dict={image: comp_images, keep_probability: 1.0})\n",
    "print(pred.shape)\n",
    "\n",
    "predict_and_display(np.squeeze(comp_images,axis=3), np.squeeze(comp_annotations, axis=3),np.squeeze(pred,axis=3), 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('image_test', comp_images)\n",
    "np.save('annotation_test', comp_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
